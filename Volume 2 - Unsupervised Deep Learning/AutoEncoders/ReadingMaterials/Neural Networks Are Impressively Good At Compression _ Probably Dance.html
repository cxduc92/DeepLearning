<!DOCTYPE html>
<!-- saved from url=(0090)https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/ -->
<html lang="en"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>Neural Networks Are Impressively Good At Compression | Probably Dance</title>

	<link rel="pingback" href="https://probablydance.com/xmlrpc.php">
	<!--[if lt IE 9]>
		<script src="https://s0.wp.com/wp-content/themes/pub/manifest/js/html5.js" type="text/javascript"></script>
	<![endif]-->

	
<!-- Async WordPress.com Remote Login -->

<link rel="dns-prefetch" href="https://s0.wp.com/">
<link rel="dns-prefetch" href="https://probablydance.wordpress.com/">
<link rel="alternate" type="application/rss+xml" title="Probably Dance » Feed" href="https://probablydance.com/feed/">
<link rel="alternate" type="application/rss+xml" title="Probably Dance » Comments Feed" href="https://probablydance.com/comments/feed/">
<link rel="alternate" type="application/rss+xml" title="Probably Dance » Neural Networks Are Impressively Good At Compression Comments Feed" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/feed/">
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s0.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1582709031h&ver=5.4.1"}};
			/*! This file is auto-generated */
			!function(e,a,t){var r,n,o,i,p=a.createElement("canvas"),s=p.getContext&&p.getContext("2d");function c(e,t){var a=String.fromCharCode;s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,e),0,0);var r=p.toDataURL();return s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,t),0,0),r===p.toDataURL()}function l(e){if(!s||!s.fillText)return!1;switch(s.textBaseline="top",s.font="600 32px Arial",e){case"flag":return!c([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])&&(!c([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!c([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]));case"emoji":return!c([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340])}return!1}function d(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(i=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},o=0;o<i.length;o++)t.supports[i[o]]=l(i[o]),t.supports.everything=t.supports.everything&&t.supports[i[o]],"flag"!==i[o]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[i[o]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(r=t.source||{}).concatemoji?d(r.concatemoji):r.wpemoji&&r.twemoji&&(d(r.twemoji),d(r.wpemoji)))}(window,document,window._wpemojiSettings);
		</script><script src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/wp-emoji-release.min.js" type="text/javascript" defer=""></script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel="stylesheet" id="all-css-0-1" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(1)" type="text/css" media="all">
<style id="wp-block-library-inline-css">
.has-text-align-justify {
	text-align:justify;
}
</style>
<!--[if IE 7]>
<link rel='stylesheet' id='manifest-ie-css'  href='https://s0.wp.com/wp-content/themes/pub/manifest/css/style_ie.css?ver=5.4.1' media='all' />
<![endif]-->
<link rel="stylesheet" id="all-css-2-1" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(2)" type="text/css" media="all">
<link rel="stylesheet" id="print-css-3-1" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/global-print.css" type="text/css" media="print">
<link rel="stylesheet" id="all-css-4-1" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(3)" type="text/css" media="all">
<style id="jetpack-global-styles-frontend-style-inline-css">
:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;}
</style>
<script>
var related_posts_js_options = {"post_heading":"h4"};
</script>
<script type="text/javascript" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(4)"></script>
<link rel="stylesheet" id="all-css-0-2" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/style(1).css" type="text/css" media="all">
<!--[if lt IE 8]>
<link rel='stylesheet' id='highlander-comments-ie7-css'  href='https://s0.wp.com/wp-content/mu-plugins/highlander-comments/style-ie7.css?m=1351637563h&#038;ver=20110606' media='all' />
<![endif]-->
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://probablydance.wordpress.com/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s0.wp.com/wp-includes/wlwmanifest.xml"> 
<link rel="prev" title="VR Will Be About Using Your Hands" href="https://probablydance.com/2016/03/25/vr-will-be-about-using-your-hands/">
<link rel="next" title="C++11 Completed RAII, Making Composition Easier" href="https://probablydance.com/2016/06/03/c11-completed-raii-making-composition-easier/">
<meta name="generator" content="WordPress.com">
<link rel="canonical" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/">
<link rel="shortlink" href="https://wp.me/p1xYfp-Dh">
<link rel="alternate" type="application/json+oembed" href="https://public-api.wordpress.com/oembed/?format=json&amp;url=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&amp;for=wpcom-auto-discovery"><link rel="alternate" type="application/xml+oembed" href="https://public-api.wordpress.com/oembed/?format=xml&amp;url=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&amp;for=wpcom-auto-discovery">
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Networks Are Impressively Good At Compression">
<meta property="og:url" content="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/">
<meta property="og:description" content="I’m trying to get into neural networks. There have been a couple big breakthroughs in the field in recent years and suddenly my side project of messing around with programming languages seeme…">
<meta property="article:published_time" content="2016-04-30T13:24:10+00:00">
<meta property="article:modified_time" content="2016-04-30T13:33:09+00:00">
<meta property="og:site_name" content="Probably Dance">
<meta property="og:image" content="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png">
<meta property="og:image:width" content="423">
<meta property="og:image:height" content="308">
<meta property="og:locale" content="en_US">
<meta name="twitter:site" content="@wordpressdotcom">
<meta name="twitter:text:title" content="Neural Networks Are Impressively Good At Compression">
<meta name="twitter:image" content="https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=640">
<meta name="twitter:card" content="summary_large_image">
<meta property="article:publisher" content="https://www.facebook.com/WordPresscom">

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://s0.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48">
<link rel="icon" type="image/x-icon" href="https://s0.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48">
<link rel="apple-touch-icon" href="https://s0.wp.com/i/webclip.png">
<link rel="openid.server" href="https://probablydance.com/?openidserver=1">
<link rel="openid.delegate" href="https://probablydance.com/">
<link rel="search" type="application/opensearchdescription+xml" href="https://probablydance.com/osd.xml" title="Probably Dance">
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com">
<meta name="application-name" content="Probably Dance"><meta name="msapplication-window" content="width=device-width;height=device-height"><meta name="msapplication-tooltip" content="I can program and like games"><meta name="msapplication-task" content="name=Subscribe;action-uri=https://probablydance.com/feed/;icon-uri=https://s0.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s0.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s0.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s0.wp.com/i/favicon.ico"><meta name="description" content="I&#39;m trying to get into neural networks. There have been a couple big breakthroughs in the field in recent years and suddenly my side project of messing around with programming languages seemed short sighted. It almost seems like we&#39;ll have real AI soon and I want to be working on that. While making my first…">
<link rel="amphtml" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/amp/"><style type="text/css" id="custom-colors-css">#site-wrapper{border-style:solid;border-width:0 2px;padding:15px 120px}#footer{border-left:2px solid;border-right:2px solid;margin-top:0;padding:30px 120px}#wpstats{margin-bottom:0;margin-top:-10px}#footer{border-top-color:#000}#footer{border-top-color:rgba(0,0,0,.1)}#infinite-handle span{background-color:#333}#site-wrapper{background-color:#fff}#footer{background-color:#fff}input[type=submit],#core-content #respond #comment-submit{color:#000}#infinite-handle span{color:#000}#infinite-handle span::before{color:#fff}#infinite-handle span::before{color:rgba(255,255,255,.4)}body{background-color:#fff}body{background-color:rgba(255,255,255,.2)}#site-wrapper{border-color:#fff}#footer{border-left-color:#fff}#footer{border-right-color:#fff}h1 a:link,h1 a:visited,h1 a:hover,h1 a:active{color:#648285}input[type=submit],#core-content #respond #comment-submit{background-color:#8ea7aa}input[type=submit],#core-content #respond #comment-submit{background:#697d80}input[type=submit],#core-content #respond #comment-submit{border-color:#526264}input[type=submit]:hover,input[type=submit]:focus,#core-content #respond #comment-submit:hover{background-color:#526264}a:link,a:visited{color:#7a6c51}h5.post-date{border-bottom-color:#9c8a6a}h5.post-date{border-bottom-color:rgba(156,138,106,.8)}.format-status .post-content{background-color:#9c8a6a}.format-status .post-content{background-color:rgba(156,138,106,.05)}html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{border-color:#000}h3 a:link,h3 a:visited,h2,.entry-content strong,h2.archive-title strong{color:#000}</style>
		<link rel="stylesheet" id="custom-css-css" type="text/css" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(5)">
		<style type="text/css"></style><link rel="stylesheet" type="text/css" id="gravatar-card-css" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/hovercard.min.css"><link rel="stylesheet" type="text/css" id="gravatar-card-services-css" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/services.min.css"></head>

<body class="post-template-default single single-post postid-2435 single-format-standard customizer-styles-applied highlander-enabled highlander-light custom-colors">

<div id="site-wrapper">
	<h1 class="vcard author" id="site-title"><a href="https://probablydance.com/" title="Home" class="fn">Probably Dance</a></h1>
	<nav id="main-nav">
			<ul>
			</ul>
	</nav>
		<div id="site-description">
		I can program and like games	</div>

<div id="core-content">


	
<div class="post-2435 post type-post status-publish format-standard hentry category-programming tag-ai tag-neural-networks" id="post-2435">
	<div class="post-content">
		<h3 class="entry-title">Neural Networks Are Impressively Good At&nbsp;Compression</h3>		<h4 class="vcard author">by <span class="fn">Malte Skarupke</span></h4>

				<div class="entry-content">
			<p>I’m trying to get into neural networks. There have been a couple big breakthroughs in the field in recent years and suddenly my side project of messing around with programming languages seemed short sighted. It almost seems like we’ll have real AI soon and I want to be working on that. While making my first couple steps into the field it’s hard to keep that enthusiasm. A lot of the field is still kinda handwavy where when you want to find out why something is used the way it’s used, the only answer you can get is “because it works like this and it doesn’t work if we change it.”</p>
<p>At least that’s my first impression. Still just dipping my toes in. But there is one thing I am very impressed with: How much data neural networks can express in how few connections.</p>
<p><span id="more-2435"></span></p>
<p>To illustrate let me draw a very simple neural network. It’s not a very interesting neural network, I’m just connecting inputs to outputs:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png"><img data-attachment-id="2441" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/1_fully_connected/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png" data-orig-size="421,307" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1_fully_connected" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=421" class="alignnone size-full wp-image-2441" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/1_fully_connected.png" alt="1_fully_connected" srcset="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png 421w, https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=300 300w" sizes="(max-width: 421px) 100vw, 421px"></a></p>
<p>And now let’s say that I want to teach this neural network the following pattern: Whenever input 1 fires, fire output 2. When input 2 fires, fire output 3. When input 3 fires, fire output 4. When input 4 fires, fire output 5. Output 1 never gets fired and input 5 never gets fired. To do that you use an algorithm called back propagation and repeatedly tell the network what output you expect for a given input, but that is not what I want to talk about here. I want to talk about the results. I’ll make the connections that the network learns stronger, and the connections that the network doesn’t learn weaker:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/2_learned.png"><img data-attachment-id="2442" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/2_learned/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/2_learned.png" data-orig-size="422,301" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2_learned" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=422" class="alignnone size-full wp-image-2442" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/2_learned.png" alt="2_learned" srcset="https://probablydance.files.wordpress.com/2016/04/2_learned.png 422w, https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=300 300w" sizes="(max-width: 422px) 100vw, 422px"></a></p>
<p>What happened here is that the weights for some connections have increased, while the weights for most connections have decreased. I haven’t talked about weights yet. Weights are what neural networks learn. When we draw networks, the nodes seem more important. But what the network actually learns and stores are weights on the connections. In the picture above the thick lines have a weight of 1, the others have a weight of 0. (weights can also go negative, and they can go up arbitrarily high)</p>
<h2>Hidden Layers</h2>
<p>A simple network like the one above can learn simple patterns like this. If we want to learn more complex patterns, we have to create a network that has more layers. Let’s insert a layer with two neurons in the middle:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png"><img data-attachment-id="2443" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/3_middle_layer/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png" data-orig-size="421,303" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="3_middle_layer" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=421" class="alignnone size-full wp-image-2443" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/3_middle_layer.png" alt="3_middle_layer" srcset="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png 421w, https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=300 300w" sizes="(max-width: 421px) 100vw, 421px"></a></p>
<p>There are many possible behaviors for those neurons in the middle, and that is the part where most of the magic happens in neural networks. It seems like picking what goes there just requires experimentation and experience. A simple neuron would be the tanh neuron which does these three steps:</p>
<ol>
<li>add up all of its inputs multiplied by their weights</li>
<li>calculate tanh() on the sum</li>
<li>fire the result to its outputs multiplied by their weights</li>
</ol>
<p>Why tanh? Because it has a couple convenient properties, and it happens to work better than other functions that have the same properties. But mostly it’s “beause it works like this and it doesn’t work when we change it.”</p>
<p>If you count the number of connections on that last picture you will notice that there are fewer than there were in the first network. There were 5*5=25 at first, now there are 5*2*2=20. That reduction would be larger if I had more input and output nodes. For 10 nodes that reduction would be from 100 connections down to 40 when inserting two nodes in the middle. That’s where the compression in the title of this blog post comes from.</p>
<p>The question is whether we can still represent the original pattern in this new representation. To show why that is not obvious, I’ll explain why it doesn’t work if you just have one middle neuron:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png"><img data-attachment-id="2444" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/4_single_middle/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png" data-orig-size="414,299" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="4_single_middle" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=414" class="alignnone size-full wp-image-2444" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/4_single_middle.png" alt="4_single_middle" srcset="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png 414w, https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=300 300w" sizes="(max-width: 414px) 100vw, 414px"></a></p>
<p>If I initialize the weights on here so that the first node fires the second output, all nodes will fire the second output:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png"><img data-attachment-id="2445" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/5_single_middle_weights/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png" data-orig-size="416,299" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5_single_middle_weights" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=416" class="alignnone size-full wp-image-2445" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/5_single_middle_weights.png" alt="5_single_middle_weights" srcset="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png 416w, https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=300 300w" sizes="(max-width: 416px) 100vw, 416px"></a></p>
<p>That one node in the middle messes up the ability for my network to learn my very simple rule. This network can not learn different behaviors for different input nodes because they all have to go through that one node in the middle. Remember that the node in the middle just adds all of its inputs, so it can not have different behaviors depending on which input it receives. The information of where a value came from gets lost in the summation.</p>
<p>So how many nodes do I need to put into the middle to still be able to learn my rule? In real neural networks you usually put hundreds of nodes into that middle layer, but what is the minimal number to learn my pattern? Before I get to the answer I need to explain one more type of neuron that enables my compression: The softmax layer. If I make my output layer a softmax layer, that means that it will look at all the activations on that layer, and that it will only fire the output with the highest activation. That’s where the “max” in the softmax comes from: It fires the max node. The “soft” part is also very important in other contexts because a softmax layer can fire more than one output, but in my case it will only ever fire one output so we’ll stay with this explanation. If I make my middle layer a tanh layer and my output layer a softmax layer, I can represent my pattern just by having two nodes in the middle:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/6_learned1.png"><img data-attachment-id="2464" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/6_learned-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/6_learned1.png" data-orig-size="415,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="6_learned" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=415" class="alignnone size-full wp-image-2464" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/6_learned1.png" alt="6_learned" srcset="https://probablydance.files.wordpress.com/2016/04/6_learned1.png 415w, https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=300 300w" sizes="(max-width: 415px) 100vw, 415px"></a></p>
<p>Here I’ve made lines with positive weights blue, and lines with negative weights red. This means that if for example the first input fires, I will get these values on the nodes:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png"><img data-attachment-id="2465" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/7_learned_first_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png" data-orig-size="413,303" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="7_learned_first_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=413" class="alignnone size-full wp-image-2465" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/7_learned_first_input1.png" alt="7_learned_first_input" srcset="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png 413w, https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=300 300w" sizes="(max-width: 413px) 100vw, 413px"></a></p>
<p>The first node activates both the middle nodes. That activates the second output node with weight two. The next two nodes are canceled out because they receive a positive weight from one of the middle nodes and a negative weight from the other. The last node is activated with weight -2. If I then run softmax on this only the top node will fire. Meaning the bottom node will not fire a negative output. Softmax suppresses everything except for the most active node.</p>
<p>This is a little bit simplified, because the tanh layer doesn’t give out nice round numbers and the softmax layer wants bigger numbers, but those complications are not necessary to understand what’s going on, so I’ll keep the numbers in this blog post simple. (the real weights in my test code are +9 and -9 on the connections going from the input layer to the middle layer, and +26 and -26 on the connections going from the middle layer to the output layer. I don’t know why those numbers specifically, that’s just where the network decided to stabilize)</p>
<p>Let’s quickly run through this for the other three cases as well:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png"><img data-attachment-id="2466" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/8_learned_second_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png" data-orig-size="417,311" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="8_learned_second_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=417" class="alignnone size-full wp-image-2466" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/8_learned_second_input1.png" alt="8_learned_second_input" srcset="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png 417w, https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=300 300w" sizes="(max-width: 417px) 100vw, 417px"></a></p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png"><img data-attachment-id="2467" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/9_learned_third_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png" data-orig-size="419,309" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="9_learned_third_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=419" class="alignnone size-full wp-image-2467" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/9_learned_third_input1.png" alt="9_learned_third_input" srcset="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png 419w, https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=300 300w" sizes="(max-width: 419px) 100vw, 419px"></a></p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png"><img data-attachment-id="2468" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/10_learned_last_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png" data-orig-size="423,308" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="10_learned_last_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=423" class="alignnone size-full wp-image-2468" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/10_learned_last_input1.png" alt="10_learned_last_input" srcset="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png 423w, https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=300 300w" sizes="(max-width: 423px) 100vw, 423px"></a></p>
<p>As you can see there is always one clear winner and then the softmax layer at the end will make sure that only that one fires and the other outputs remain quiet. When I first saw this behavior I was quite impressed. In fact I saw this behavior on a network with eleven inputs, eleven outputs and just two middle nodes. Can you think of how the above layer would work with eleven inputs? It seems like there’s only four possible combinations for these weights and we’ve used all of them, right? You’re underestimating neural networks. It’s quite impressive how they will try to squeeze any pattern that you throw at them into what’s available. For eleven inputs and eleven outputs it looks like this:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png"><img data-attachment-id="2473" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/14_eleven_numbers-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png" data-orig-size="500,793" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="14_eleven_numbers" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=189" data-large-file="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=500" class="alignnone size-full wp-image-2473" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/14_eleven_numbers1.png" alt="14_eleven_numbers" srcset="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png 500w, https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=95 95w, https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=189 189w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>That is a lot of connections and a lot of numbers. The network has now decided to make some connections stronger and other connections weaker. I couldn’t keep using colors and line-style to visualize different strengths because now there are a lot of different values. Whenever I tried to simplify and not use numbers I’d break the network. So instead I just show the numbers. The upper number on each node is the weight of the connection to/from the upper node in the middle layer, and the lower number is the weight of the connection to/from the lower node in the middle layer.</p>
<p>Let’s walk through a random example and see how it works:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png"><img data-attachment-id="2474" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/15_eleven_numbers_example/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png" data-orig-size="507,799" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="15_eleven_numbers_example" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=190" data-large-file="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=507" class="alignnone size-full wp-image-2474" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/15_eleven_numbers_example.png" alt="15_eleven_numbers_example" srcset="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png 507w, https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=95 95w, https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=190 190w" sizes="(max-width: 507px) 100vw, 507px"></a></p>
<p>The node with the largest output value (72 = -10 * -4 + 8 * 4) is the one we want to fire, and softmax will select that. In this picture I’m just multiplying the numbers linearly because the weights on the left actually already have tanh applied (and were then multiplied by 10 to get them into the range -10 to 10 which is slightly nicer for pictures than the range -1 to 1). I can do that in this case since I only ever fire one input. And if I can just do linear math the example is easier to follow.</p>
<p>I’ll post a second example to show that the weights will activate the desired output for any input:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/16_second_example.png"><img data-attachment-id="2475" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/16_second_example/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/16_second_example.png" data-orig-size="496,790" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="16_second_example" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=188" data-large-file="https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=496" class="alignnone size-full wp-image-2475" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/16_second_example.png" alt="16_second_example" srcset="https://probablydance.files.wordpress.com/2016/04/16_second_example.png 496w, https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=94 94w, https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=188 188w" sizes="(max-width: 496px) 100vw, 496px"></a></p>
<p>Here also for my given input n, output n+1 had the highest value at the end and softmax will make that output fire. You could go through a couple more examples and convince yourself that this network has learned the pattern that I want it to learn.</p>
<p>I don’t know about you, but I think this is quite impressive. For the small first network I think I could have figured out how to put the numbers in manually. (once you know the trick that the nodes can cancel each other out it’s easy) For all the connections on the larger network you would have to be very good at balancing these weights, and I honestly don’t think I could have done this by hand. The neural network however seems to just figure this out. Or rather: it figures this out if you use a tanh layer in the middle and a softmax layer at the end. If you don’t, it will stop working.</p>
<p>Since I’m using real numbers now I might as well explain how softmax works. Softmax uses the number at the end as an exponent and then normalizes the column afterwards. If I use 2^x it should be obvious that 2^56, the highest number, is a lot bigger than 2^44, the next highest number. If I have 2^56 in the column and I normalize it, all the other activations will go very close to zero and the output that I want to fire will be close to 1. Also by using an exponent I get no negative numbers. 2^-96 is just a number that’s very close to zero. The standard is to use e^x instead of 2^x, and I also use that, it’s just that as a programmer I find it easier to explain and easier to understand using powers of two.</p>
<h2>How This Works</h2>
<p>With that information I can give a bit of an intuition why this happens to work if you use tanh and softmax: When using softmax, the connections can keep on improving the chance of their desired output just by making their own weights bigger. In fact since I just used linear math in my explanation above and didn’t need to run tanh() on anything, couldn’t softmax have learned those weighs even without using a tanh layer? In theory it could, but in practice it will keep on bumping up the numbers to get small improvements and you will very quickly overflow floating point numbers. The tanh layer in the middle is then just responsible for keeping the numbers small: it clamps its outputs to the range -1 to 1, and the inputs won’t grow past a certain point either because at some point a bigger number just means that the output goes from 0.995 to 0.997. But since they can usually still get a small improvement you don’t lose that nice property of softmax where neurons can keep on edging out small improvements over each other.</p>
<p>So if you just use softmax your weights will explode and if you just use tanh your weights will stagnate too soon before a good solution emerges. If you use both you get nice greedy behavior where the connections keep on looking for better solutions, but you also keep the weights from exploding.</p>
<p>Now all I’ve shown is that my network can learn the rule that when input n fires, it needs to fire output n+1. It should be easy to see that just by creating a different permutation of the weights of the connections I can teach my network that for any input neuron x, it should fire any other output neuron y. The impressive part is that without the middle layer I would have needed 11*11 = 121 connections to have a network that can learn any combination, and with that middle layer I can do it in only 11*2*2 = 44 connections.</p>
<p>Eleven inputs and outputs is close to the limit for what you can do with two nodes in the middle. If you ask it to do much more the weights will fluctuate and they will keep on stepping on each others toes. But with three nodes in the middle I can learn these patterns for something like thirty inputs and outputs, and with four nodes, I can learn direct connections for more than a hundred inputs and outputs. It doesn’t grow linearly because the number of combinations doesn’t grow linearly. Luckily the back propagation algorithm scales with the number of connections, not with the number of combinations. So with a linear increase in computation cost I get a super-linear increase in the amount of stuff I can learn.</p>
<h2>Outlook and Conclusions</h2>
<p>I’m still just getting started with neural networks, and real networks look nothing like my tiny examples above. I don’t know how many neurons people actually use nowadays, but even small examples talk about hundreds of neurons. At that point it’s more difficult to understand what your network has learned. You can’t visualize it as easily as the above pictures. In fact even the eleven neuron picture is difficult to understand because you can’t just look at the strong connections. Even the weak connections are important. If that middle layer had 700 neurons, then good luck getting a picture of which connections are actually important. Maybe a bunch of weak connections add up to build the output you wanted and one random strong connection suppresses all the unwanted outputs that you didn’t want.</p>
<p>But I hope I have given you an intuition for how neural networks can compress patterns in few weights. They use the full range of the weights to the point where a connection activated with a strong input can mean something entirely different than the same connection activated with a weak input. And best of all I didn’t have to teach them to do this. They just start behaving like this if you force them to express a complex pattern in few connections.</p>
<div id="jp-post-flair" class="sharedaddy sd-like-enabled sd-sharing-enabled"><div class="sharedaddy sd-sharing-enabled"><div class="robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing"><h3 class="sd-title">Share this:</h3><div class="sd-content"><ul><li class="share-twitter"><a rel="nofollow noopener noreferrer" data-shared="sharing-twitter-2435" class="share-twitter sd-button share-icon" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?share=twitter&amp;nb=1" target="_blank" title="Click to share on Twitter"><span>Twitter</span></a></li><li class="share-facebook"><a rel="nofollow noopener noreferrer" data-shared="sharing-facebook-2435" class="share-facebook sd-button share-icon" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?share=facebook&amp;nb=1" target="_blank" title="Click to share on Facebook"><span>Facebook</span></a></li><li class="share-end"></li></ul></div></div></div><div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-loaded" id="like-post-wrapper-22872755-2435-5ead7a5005c3c" data-src="//widgets.wp.com/likes/index.html?ver=20190321#blog_id=22872755&amp;post_id=2435&amp;origin=probablydance.wordpress.com&amp;obj_id=22872755-2435-5ead7a5005c3c&amp;domain=probablydance.com" data-name="like-post-frame-22872755-2435-5ead7a5005c3c"><h3 class="sd-title">Like this:</h3><div class="likes-widget-placeholder post-likes-widget-placeholder" style="height: 55px; display: none;"><span class="button"><span>Like</span></span> <span class="loading">Loading...</span></div><iframe class="post-likes-widget jetpack-likes-widget" name="like-post-frame-22872755-2435-5ead7a5005c3c" height="55px" width="100%" frameborder="0" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/index.html"></iframe><span class="sd-text-color"></span><a class="sd-link-color"></a></div>
<div id="jp-relatedposts" class="jp-relatedposts" style="display: block;">
	<h3 class="jp-relatedposts-headline"><em>Related</em></h3>
<div class="jp-relatedposts-items jp-relatedposts-items-minimal"><p class="jp-relatedposts-post jp-relatedposts-post0" data-post-id="9884" data-post-format="false"><span class="jp-relatedposts-post-title"><a class="jp-relatedposts-post-a" href="https://probablydance.com/2020/01/29/why-video-game-ai-does-not-use-machine-learning/" title="Why Video Game AI does not Use Machine Learning

I used to be an AI programmer working on video games, and I&#39;m currently trying to learn machine learning. As part of this I find myself having to repeatedly explain why video games don&#39;t use machine learning. People seem to find it interesting enough because it&#39;s not just the obvious…" data-origin="2435" data-position="0">Why Video Game AI does not Use Machine Learning</a></span><span class="jp-relatedposts-post-context">In "Games"</span></p><p class="jp-relatedposts-post jp-relatedposts-post1" data-post-id="2311" data-post-format="false"><span class="jp-relatedposts-post-title"><a class="jp-relatedposts-post-a" href="https://probablydance.com/2016/02/27/functional-programming-is-not-popular-because-it-is-weird/" title="Functional Programming Is Not Popular Because It Is Weird

I&#39;ve seen people be genuinely puzzled about why functional programming is not more popular. For example I&#39;m currently reading &quot;Out of the Tar Pit&quot; where after arguing for functional programming the authors say Still, the fact remains that such arguments have been insufficient to result in widespread adoption of functional…" data-origin="2435" data-position="1">Functional Programming Is Not Popular Because It Is Weird</a></span><span class="jp-relatedposts-post-context">In "Programming"</span></p><p class="jp-relatedposts-post jp-relatedposts-post2" data-post-id="6655" data-post-format="false"><span class="jp-relatedposts-post-title"><a class="jp-relatedposts-post-a" href="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/" title="I Wrote The Fastest Hashtable

I had to get there eventually. I had a blog post called &quot;I Wrote a Fast Hashtable&quot; and another blog post called &quot;I Wrote a Faster Hashtable.&quot; Now I finally wrote the fastest hashtable. And by that I mean that I have the fastest lookups of any hashtable I could…" data-origin="2435" data-position="2">I Wrote The Fastest Hashtable</a></span><span class="jp-relatedposts-post-context">In "Programming"</span></p></div></div></div>					</div>
	</div>
	<div class="post-meta">
						<div class="post-date"><span>Published:</span> <abbr class="published" title="2016-04-30T06:24:10-0700"><a href="https://probablydance.com/2016/04/30/">April 30, 2016</a></abbr></div>
		<div class="categories"><span>Filed Under:</span> <a href="https://probablydance.com/category/programming/" rel="category tag">Programming</a></div>
		<span>Tags:</span> <a href="https://probablydance.com/tag/ai/" rel="tag">ai</a> : <a href="https://probablydance.com/tag/neural-networks/" rel="tag">neural networks</a>	</div>
</div>
	<div id="comments">
	
			<h3 id="comments">17 Comments to “Neural Networks Are Impressively Good At&nbsp;Compression”</h3>

		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"></div>
		</div>

		<ol class="commentlist">
				<li class="comment byuser comment-author-graphific even thread-even depth-1 parent highlander-comment" id="comment-2695">
				<div id="div-comment-2695" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/866ac17d713ed49c713e14e9b4ba34ab.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-866ac17d713ed49c713e14e9b4ba34ab-0">			<cite class="fn"><a href="http://gravatar.com/graphific" rel="external nofollow ugc" class="url">graphific</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2695">
			April 30, 2016 at 10:21				</a>
						</div>

		<p>congratulations, not sure if you heard of Auto-Encoders before, but thats essentially what you have been constructing. nice! See ie <a href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/" rel="nofollow ugc">http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/</a></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2695#respond" data-commentid="2695" data-postid="2435" data-belowelement="div-comment-2695" data-respondelement="respond" aria-label="Reply to graphific">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor odd alt depth-2 highlander-comment" id="comment-2703">
				<div id="div-comment-2703" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-32d3ef171bc897317c4a77a83f44fbcb-0">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow ugc" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2703">
			May 1, 2016 at 10:48				</a>
						</div>

		<p>Thanks! That is indeed exactly what I’ve been constructing. I’m still new to the field and was just playing around with neurons to get a better understanding for them, so it doesn’t surprise me that this is a known thing.</p>
<p>It’s weird how you can miss things that are blindingly obvious in hindsight. Like when I talked about permutations above I should have realized that I can just make the network learn to always make the output equal to the input. And then I can get all other patterns just by creating a permutation of the weights. That’s what auto encoders do and that would have been a simpler problem to solve and to explain, and it would have given me the same solution.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2703#respond" data-commentid="2703" data-postid="2435" data-belowelement="div-comment-2703" data-respondelement="respond" aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2696">
				<div id="div-comment-2696" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/e214f5c143b40458c473bef6ee05823e" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-e214f5c143b40458c473bef6ee05823e-0">			<cite class="fn">Martin Cohen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2696">
			April 30, 2016 at 16:14				</a>
						</div>

		<p>I don’t know if this is relevant, but the logistic curve (which is a scaled and shifted tanh) and the normal cdf are fairly close, differing by at most 0.044. If the logistic curve is modified so that its slope match the normal cdf at zero, the difference is at most 0.017. I wonder how the results using a shifted normal cdf would differ from the tanh you use.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2696#respond" data-commentid="2696" data-postid="2435" data-belowelement="div-comment-2696" data-respondelement="respond" aria-label="Reply to Martin Cohen">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor odd alt depth-2 parent highlander-comment" id="comment-2704">
				<div id="div-comment-2704" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-32d3ef171bc897317c4a77a83f44fbcb-1">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow ugc" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2704">
			May 1, 2016 at 11:11				</a>
						</div>

		<p>A lot of different activation functions have been tried and wikipedia has a good list of them:<br>
<a href="https://en.wikipedia.org/wiki/Activation_function" rel="nofollow ugc">https://en.wikipedia.org/wiki/Activation_function</a></p>
<p>The ones you mentioned are in there, but I don’t know why they’re not used more often.</p>
<p>Google has a great website where you can play around with neural networks, and one of the parameters on there is the activation function:<br>
<a href="http://playground.tensorflow.org/" rel="nofollow ugc">http://playground.tensorflow.org</a></p>
<p>You can try Tanh, Sigmoid (which I think is what you mean when you say logistic curve) and ReLU activation functions. For the initial setup and the initial problem on the website if I select Tanh, the network arrives at a solution in something like 50 iterations. Using Sigmoid I get an approximate solution and even after more than 5000 iterations I don’t get the right solution. Trying a second time with a new random starting position it did arrive at a correct solution but took 900 iterations to get there. ReLU solves the problem in something like 30 iterations.</p>
<p>I don’t know why Sigmoid should be so very bad at that problem. It seems on the surface to be very similar to Tanh, as you correctly point out. But for some reason it seems to be more conservative than Tanh. And sometimes that means it’s too conservative so when it arrives at an approximate solution it stays there.</p>
<p>That’s the best reason I can give you for why Tanh is better: It seems to be less conservative than Sigmoid. I could probably give you a better reason if I spend a bit of time debugging this and watching it in more detail, but I don’t think that’s worth doing for me since I’m still new to the field. I’ll just use the things that have proven good experimentally.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2704#respond" data-commentid="2704" data-postid="2435" data-belowelement="div-comment-2704" data-respondelement="respond" aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-3 highlander-comment" id="comment-2716">
				<div id="div-comment-2716" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/e31d7c3f1f052f5694a083055887156b" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-e31d7c3f1f052f5694a083055887156b-0">			<cite class="fn"><a href="http://gravatar.com/pse1202" rel="external nofollow ugc" class="url">Sam Park</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2716">
			May 9, 2016 at 00:10				</a>
						</div>

		<p>In many cases, ReLU and its modifications are used instead of sigmoid or tanh. The main reason is that it is much more faster. Exponential functions are very expensive when calculating sigmoid functions compared to the simplicity of ReLU.</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2697">
				<div id="div-comment-2697" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/6568504bfd4f071c1847be37aaf20ec3" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-6568504bfd4f071c1847be37aaf20ec3-0">			<cite class="fn">Al Rahat</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2697">
			April 30, 2016 at 19:52				</a>
						</div>

		<p>Not sure if you’ve seen this paper: <a href="http://arxiv.org/pdf/1511.06085v5.pdf" rel="nofollow ugc">http://arxiv.org/pdf/1511.06085v5.pdf</a> but it seems that they take what you wrote about to the next level.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2697#respond" data-commentid="2697" data-postid="2435" data-belowelement="div-comment-2697" data-respondelement="respond" aria-label="Reply to Al Rahat">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor even depth-2 highlander-comment" id="comment-2708">
				<div id="div-comment-2708" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-32d3ef171bc897317c4a77a83f44fbcb-2">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow ugc" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2708">
			May 1, 2016 at 15:33				</a>
						</div>

		<p>Love it, thanks for the link!</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2708#respond" data-commentid="2708" data-postid="2435" data-belowelement="div-comment-2708" data-respondelement="respond" aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2698">
				<div id="div-comment-2698" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/c2a2c0b6dd4808989adcd863123fa585" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-c2a2c0b6dd4808989adcd863123fa585-0">			<cite class="fn">leo</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2698">
			April 30, 2016 at 20:09				</a>
						</div>

		<p>Have you thought of entering a compression algorithm for the Hutter prize?</p>
<p><a href="https://en.wikipedia.org/wiki/Hutter_Prize" rel="nofollow ugc">https://en.wikipedia.org/wiki/Hutter_Prize</a></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2698#respond" data-commentid="2698" data-postid="2435" data-belowelement="div-comment-2698" data-respondelement="respond" aria-label="Reply to leo">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor even depth-2 highlander-comment" id="comment-2707">
				<div id="div-comment-2707" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-32d3ef171bc897317c4a77a83f44fbcb-3">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow ugc" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2707">
			May 1, 2016 at 15:23				</a>
						</div>

		<p>I’m not sure if this would work for text compression. It works as long as you have nice clean patterns like I have, but the problem is that you get fuzzy results for more complex cases. Like let’s say your network is trying to learn the word “HELLO”; you have four input nodes: E, H, L, and O; and five output nodes: E, H, L, O and ‘end of text’. That setup will learn the word, but it has to learn that for the letter L it has to either output a second L or an O.</p>
<p>So now your network will either output “HELLO” or “HELO” or “HELLLO” or any other multiple of Ls. (though they get less likely the further you are from the truth) There are ways to solve this and that is the next thing I want to learn in neural networks, but I think once you leave simple examples you always have that fuzziness in there. And fuzziness is not something you want in text compression 😉</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2707#respond" data-commentid="2707" data-postid="2435" data-belowelement="div-comment-2707" data-respondelement="respond" aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2699">
				<div id="div-comment-2699" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/bf239d8fd2063bb9776944028e649c62.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-bf239d8fd2063bb9776944028e649c62-0">			<cite class="fn">Pablo Arias</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2699">
			April 30, 2016 at 21:17				</a>
						</div>

		<p>Why tanh? Because it has a couple convenient properties, and it happens to work better than other functions that have the same properties. But mostly it’s “beause it works like this and it doesn’t work when we change it.”</p>
<p>Not completly true. tanh() cane to replace a very popular function in NN, sinh(). It works better because 1) it looks more like the way real neurons trigger, and 2) it has a stepper transition, it dwells less in the meta stable region</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2699#respond" data-commentid="2699" data-postid="2435" data-belowelement="div-comment-2699" data-respondelement="respond" aria-label="Reply to Pablo Arias">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-2 highlander-comment" id="comment-2700">
				<div id="div-comment-2700" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/e214f5c143b40458c473bef6ee05823e" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-e214f5c143b40458c473bef6ee05823e-1">			<cite class="fn">Martin Cohen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2700">
			April 30, 2016 at 22:07				</a>
						</div>

		<p>Are you sure you mean “sinh”? That get very large very fast. Maybe inverse tan?</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2700#respond" data-commentid="2700" data-postid="2435" data-belowelement="div-comment-2700" data-respondelement="respond" aria-label="Reply to Martin Cohen">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-tgsmith61591 odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2701">
				<div id="div-comment-2701" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/31ccee0370328a7c894902c0a70373f7.png" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-31ccee0370328a7c894902c0a70373f7-0">			<cite class="fn">tgsmith61591</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2701">
			May 1, 2016 at 07:33				</a>
						</div>

		<p>Actually worth noting that contemporary research suggests the rectifier (max(x,0)) to be the most biologically plausible activation function, as it tends to create a more sparse network. But, there is no silver bullet. In that sense, I have to disagree with your “it works this way just because, and if we change it, it won’t” assertion. </p>
<p>Source: <a href="http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf" rel="nofollow ugc">http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf</a></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2701#respond" data-commentid="2701" data-postid="2435" data-belowelement="div-comment-2701" data-respondelement="respond" aria-label="Reply to tgsmith61591">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor even depth-2 highlander-comment" id="comment-2706">
				<div id="div-comment-2706" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-32d3ef171bc897317c4a77a83f44fbcb-4">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow ugc" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2706">
			May 1, 2016 at 15:12				</a>
						</div>

		<p>Yeah I like ReLU much more than tanh because it’s something that was at least arrived at by design. I can understand the motivation behind it and I can build a better mental model for it than for Tanh.</p>
<p>That being said if I use ReLU for the middle layer here, I need four nodes in the middle instead of two. If this was a real compression algorithm and if my compressed data suddenly became twice as large, that would be a very bad change. So ReLU is not that great a choice at least for this specific problem. But then maybe ReLU does better once I have more connections because then Tanh will start to trample over its own constructions all the time while ReLU nodes tend to get out of each others way. But see, that’s where it gets too handwavy for me again…</p>
<p>And that paper is a typical paper from neural networks including the language that I don’t like. For example they have a part about softplus where they essentially say “you’d think that softplus has the same benefits as ReLU without the downsides, but our experiments show that that’s not the case. Here’s an idea for why that might be.” And then they just leave it at that. There’s some rigor missing here. If you put out an idea like that you should at least come up with some test for that idea and show that your idea passes that test. Any test would have been better than just leaving it like this. Here’s the sentence in question: “We hypothesize that the hard non-linearities do not hurt so long as the gradient can propagate along some paths, i.e., that some of the hidden units in each layer are non-zero. With the credit and blame assigned to these ON units rather than distributed more evenly, we hypothesize that optimization is easier.”</p>
<p>It’s a nice story and it’s plausible, but I can come up with lots of plausible stories. Like my explanation above where I say that the hard zeros help because without it nodes tend to step on each others toes more often when they optimize. That is something that I have observed, especially if certain outputs are more common in the data. Things that are more common tend to trample all over your less common cases. Batch updating seems to help with that, and the hard zeros of ReLU nodes should also help with that. Is my explanation plausible? Yes. Would I write this theory in a paper without at least some test to falsify it? No. (oh and the way you’d falsify this idea is that you’d set up a test where some outputs are far more common than others and you show that other methods trample all over the weights of less common cases, but ReLU doesn’t. You’d have to watch individual weights in your network to confirm or deny this. If you see that ReLU is trampling over rare cases just as much as other methods are, then the story is not true no matter how plausible it sounded)</p>
<p>Since their paper is so much about sparsity, I would have wanted them to test that theory specifically. Like if sparsity helps, couldn’t you use that knowledge to improve tanh()? Just force some values to zero and keep them there forever. If sparsity really helps, you would expect the performance of tanh to also increase. They didn’t do a test like this. Instead all of their theories are supported by the fact that “it works like this.”</p>
<p>All that being said I think they arrived at a good model with ReLU. And obviously you can get to really good results by constantly coming up with new things that work. But my experience has shown that you can get better results if you know why they work. (and not just if you think you know why they work)</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2706#respond" data-commentid="2706" data-postid="2435" data-belowelement="div-comment-2706" data-respondelement="respond" aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2705">
				<div id="div-comment-2705" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/522e14016606fa348941f854ddd5fb8c" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-522e14016606fa348941f854ddd5fb8c-0">			<cite class="fn">Binesh</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2705">
			May 1, 2016 at 14:41				</a>
						</div>

		<p>I think the reason tanh works better is because it’s centered at zero.. Or tanh(0) = 0 whereas sigmoid(0) = .5… If you work it through, you’ll see that as you add layers this starts pushing all the nodes towards higher and higher values…</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2705#respond" data-commentid="2705" data-postid="2435" data-belowelement="div-comment-2705" data-respondelement="respond" aria-label="Reply to Binesh">Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-2 highlander-comment" id="comment-2709">
				<div id="div-comment-2709" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/e214f5c143b40458c473bef6ee05823e" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-e214f5c143b40458c473bef6ee05823e-2">			<cite class="fn">Martin Cohen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2709">
			May 1, 2016 at 15:49				</a>
						</div>

		<p>I think I said a shifted sigmoid, which is, after scaling, identical to tanh.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2709#respond" data-commentid="2709" data-postid="2435" data-belowelement="div-comment-2709" data-respondelement="respond" aria-label="Reply to Martin Cohen">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-pirateyoshi odd alt thread-odd thread-alt depth-1 highlander-comment" id="comment-3084">
				<div id="div-comment-3084" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/3c83b477629072469dc3898e1629024f(1).png" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-3c83b477629072469dc3898e1629024f-0">			<cite class="fn">Ziru</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-3084">
			April 22, 2017 at 00:54				</a>
						</div>

		<p>Great read. Thanks for taking the time to write it ^^</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=3084#respond" data-commentid="3084" data-postid="2435" data-belowelement="div-comment-3084" data-respondelement="respond" aria-label="Reply to Ziru">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1 highlander-comment" id="comment-4339">
				<div id="div-comment-4339" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/4ccf320bd016b7a6cdd8c75bbba88cab" class="avatar avatar-48 grav-hashed grav-hijack" height="48" width="48" id="grav-4ccf320bd016b7a6cdd8c75bbba88cab-0">			<cite class="fn">Egg Syntax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-4339">
			October 12, 2018 at 17:41				</a>
						</div>

		<p>Probably the best intro article on NN that I’ve ever seen, nice work!</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=4339#respond" data-commentid="4339" data-postid="2435" data-belowelement="div-comment-4339" data-respondelement="respond" aria-label="Reply to Egg Syntax">Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		</ol>

		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"></div>
		</div>
 	
		<div id="respond" class="comment-respond js">
		<h3 id="reply-title" class="comment-reply-title">Leave a Reply <small><a rel="nofollow" id="cancel-comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#respond" style="display:none;">Cancel reply</a></small></h3><form action="https://probablydance.com/wp-comments-post.php" method="post" id="commentform" class="comment-form"><input type="hidden" id="highlander_comment_nonce" name="highlander_comment_nonce" value="2076187f2e"><input type="hidden" name="_wp_http_referer" value="/2016/04/30/neural-networks-are-impressively-good-at-compression/">
<input type="hidden" name="hc_post_as" id="hc_post_as" value="guest">

<div class="comment-form-field comment-textarea">
	
	<div id="comment-form-comment"><textarea aria-hidden="true" tabindex="-1" style="position: absolute; top: -999px; left: 0px; right: auto; bottom: auto; border: 0px; padding: 0px; box-sizing: content-box; overflow-wrap: break-word; overflow: hidden; transition: none 0s ease 0s; height: 0px !important; min-height: 0px !important; font-family: Arial, Helvetica, Tahoma, Verdana, sans-serif; font-size: 14px; font-weight: 400; font-style: normal; letter-spacing: 0px; text-transform: none; text-decoration: none solid rgba(0, 0, 0, 0.7); word-spacing: 0px; text-indent: 0px; line-height: normal; width: 628px;" class="autosizejs "></textarea><textarea id="comment" name="comment" title="Enter your comment here..." placeholder="Enter your comment here..." style="height: 36px; overflow: hidden; overflow-wrap: break-word; resize: none;"></textarea></div>
</div>

<div id="comment-form-identity" style="display: none;">
	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			<li class="selected" style="display:none;">
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-form-guest" id="postas-guest" class="nascar-signin-link" title="Login via Guest">
									</a>
			</li>
			<li>
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-form-load-service:WordPress.com" id="postas-wordpress" class="nascar-signin-link" title="Login via WordPress.com">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-form-load-service:Twitter" id="postas-twitter" class="nascar-signin-link" title="Login via Twitter">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-form-load-service:Facebook" id="postas-facebook" class="nascar-signin-link" title="Login via Facebook">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg>				</a>
			</li>
		</ul>
	</div>

	<div id="comment-form-guest" class="comment-form-service selected">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
<a href="https://gravatar.com/site/signup/" target="_blank">				<img src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/ad516503a11cd5ca435acc9bb6523536" alt="Gravatar" width="25" class="no-grav grav-hashed grav-hijack" id="grav-ad516503a11cd5ca435acc9bb6523536-0">
</a>			</div>

				<div class="comment-form-fields">
				<div class="comment-form-field comment-form-email">
					<label for="email">Email <span class="required">(required)</span> <span class="nopublish">(Address never made public)</span></label>
					<div class="comment-form-input"><input id="email" name="email" type="email" value=""></div>
				</div>
				<div class="comment-form-field comment-form-author">
					<label for="author">Name <span class="required">(required)</span></label>
					<div class="comment-form-input"><input id="author" name="author" type="text" value=""></div>
				</div>
				<div class="comment-form-field comment-form-url">
					<label for="url">Website</label>
					<div class="comment-form-input"><input id="url" name="url" type="url" value=""></div>
				</div>
			</div>
			
		</div>
	</div>

	<div id="comment-form-wordpress" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/ad516503a11cd5ca435acc9bb6523536" alt="WordPress.com Logo" width="25" class="no-grav grav-hashed grav-hijack" id="grav-ad516503a11cd5ca435acc9bb6523536-1">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="wp_avatar" id="wordpress-avatar" class="comment-meta-wordpress" value="">
				<input type="hidden" name="wp_user_id" id="wordpress-user_id" class="comment-meta-wordpress" value="">
				<input type="hidden" name="wp_access_token" id="wordpress-access_token" class="comment-meta-wordpress" value="">
						<p class="comment-form-posting-as pa-wordpress">
			<strong></strong>
			You are commenting using your WordPress.com account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;wordpress&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/ad516503a11cd5ca435acc9bb6523536" alt="Google photo" width="25" class="no-grav grav-hashed grav-hijack" id="grav-ad516503a11cd5ca435acc9bb6523536-2">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="googleplus_avatar" id="googleplus-avatar" class="comment-meta-googleplus" value="">
				<input type="hidden" name="googleplus_user_id" id="googleplus-user_id" class="comment-meta-googleplus" value="">
				<input type="hidden" name="googleplus_access_token" id="googleplus-access_token" class="comment-meta-googleplus" value="">
						<p class="comment-form-posting-as pa-googleplus">
			<strong></strong>
			You are commenting using your Google account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;googleplus&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" x="0px" y="0px" viewBox="0 0 60 60"><path fill="#519bf7" d="M56.3,30c0,-1.6 -0.2,-3.4 -0.6,-5h-3.1H42.2H30v10.6h14.8C44,39.3 42,42 39.1,43.9l8.8,6.8C53,46 56.3,39 56.3,30z"></path><path fill="#3db366" d="M30,57.5c6.7,0 13.1,-2.4 17.9,-6.8l-8.8,-6.8c-2.5,1.6 -5.6,2.4 -9.1,2.4c-7.2,0 -13.3,-4.7 -15.4,-11.2l-9.3,7.1C9.8,51.3 19.1,57.5 30,57.5z"></path><path fill="#fdc600" d="M5.3,42.2l9.3,-7.1c-0.5,-1.6 -0.8,-3.3 -0.8,-5.1s0.3,-3.5 0.8,-5.1l-9.3,-7.1C3.5,21.5 2.5,25.6 2.5,30S3.5,38.5 5.3,42.2z"></path><path fill="#f15b44" d="M40.1,17.4l8,-8C43.3,5.1 37,2.5 30,2.5C19.1,2.5 9.8,8.7 5.3,17.8l9.3,7.1c2.1,-6.5 8.2,-11.1 15.4,-11.1C33.9,13.7 37.4,15.1 40.1,17.4z"></path></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-twitter" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/ad516503a11cd5ca435acc9bb6523536" alt="Twitter picture" width="25" class="no-grav grav-hashed grav-hijack" id="grav-ad516503a11cd5ca435acc9bb6523536-3">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="twitter_avatar" id="twitter-avatar" class="comment-meta-twitter" value="">
				<input type="hidden" name="twitter_user_id" id="twitter-user_id" class="comment-meta-twitter" value="">
				<input type="hidden" name="twitter_access_token" id="twitter-access_token" class="comment-meta-twitter" value="">
						<p class="comment-form-posting-as pa-twitter">
			<strong></strong>
			You are commenting using your Twitter account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;twitter&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-facebook" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/ad516503a11cd5ca435acc9bb6523536" alt="Facebook photo" width="25" class="no-grav grav-hashed grav-hijack" id="grav-ad516503a11cd5ca435acc9bb6523536-4">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="fb_avatar" id="facebook-avatar" class="comment-meta-facebook" value="">
				<input type="hidden" name="fb_user_id" id="facebook-user_id" class="comment-meta-facebook" value="">
				<input type="hidden" name="fb_access_token" id="facebook-access_token" class="comment-meta-facebook" value="">
						<p class="comment-form-posting-as pa-facebook">
			<strong></strong>
			You are commenting using your Facebook account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;facebook&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>


	<div id="comment-form-load-service" class="comment-form-service">
		<div class="comment-form-posting-as-cancel"><a href="javascript:HighlanderComments.cancelExternalWindow();">Cancel</a></div>
		<p>Connecting to %s</p>
	</div>

</div>

<script type="text/javascript">
var highlander_expando_javascript = function(){
	var input = document.createElement( 'input' ),
	    comment = jQuery( '#comment' );

	if ( 'placeholder' in input ) {
		comment.attr( 'placeholder', jQuery( '.comment-textarea label' ).remove().text() );
	}

	// Expando Mode: start small, then auto-resize on first click + text length
	jQuery( '#comment-form-identity' ).hide();
	jQuery( '#comment-form-subscribe' ).hide();
	jQuery( '#commentform .form-submit' ).hide();

	comment.css( { 'height':'10px' } ).one( 'focus', function() {
		var timer = setInterval( HighlanderComments.resizeCallback, 10 )
		jQuery( this ).animate( { 'height': HighlanderComments.initialHeight } ).delay( 100 ).queue( function(n) { clearInterval( timer ); HighlanderComments.resizeCallback(); n(); } );
		jQuery( '#comment-form-identity' ).slideDown();
		jQuery( '#comment-form-subscribe' ).slideDown();
		jQuery( '#commentform .form-submit' ).slideDown();
	});
}
jQuery(document).ready( highlander_expando_javascript );
</script>

<div id="comment-form-subscribe" style="display: none;">
	<p class="comment-subscription-form"><input type="checkbox" name="subscribe" id="subscribe" value="subscribe" style="width: auto;"> <label class="subscribe-label" id="subscribe-label" for="subscribe" style="display: inline;">Notify me of new comments via email.</label></p><p class="post-subscription-form"><input type="checkbox" name="subscribe_blog" id="subscribe_blog" value="subscribe" style="width: auto;"> <label class="subscribe-label" id="subscribe-blog-label" for="subscribe_blog" style="display: inline;">Notify me of new posts via email.</label></p></div>




<p class="form-submit" style="display: none;"><input name="submit" type="submit" id="comment-submit" class="submit" value="Post Comment"> <input type="hidden" name="comment_post_ID" value="2435" id="comment_post_ID">
<input type="hidden" name="comment_parent" id="comment_parent" value="0">
</p><p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="5f2ffcfe4f"></p>
<input type="hidden" name="genseq" value="1588427344">
<p style="display: none;"></p><input type="hidden" id="ak_js" name="ak_js" value="1588427345473"></form>	</div><!-- #respond -->
	<div style="clear: both"></div><p class="akismet_comment_form_privacy_notice">This site uses Akismet to reduce spam. <a href="https://akismet.com/privacy/" target="_blank" rel="nofollow noopener">Learn how your comment data is processed</a>.</p></div>
	<div class="navigation">
		<div class="prev"><a href="https://probablydance.com/2016/03/25/vr-will-be-about-using-your-hands/" rel="prev">« Previous Post</a></div>
		<div class="next"><a href="https://probablydance.com/2016/06/03/c11-completed-raii-making-composition-easier/" rel="next">Next Post »</a></div>
	</div>


</div><!-- #core-content -->


</div><!-- #site-wrapper -->

<div id="footer">

	
<div id="supplementary" class="one">

		<div id="first" class="widget-area" role="complementary">
		<aside id="search-2" class="widget widget_search"><form role="search" method="get" id="searchform" class="searchform" action="https://probablydance.com/">
				<div>
					<label class="screen-reader-text" for="s">Search for:</label>
					<input type="text" value="" name="s" id="s">
					<input type="submit" id="searchsubmit" value="Search">
				</div>
			</form></aside>		<aside id="recent-posts-2" class="widget widget_recent_entries">		<h4 class="widget-title">Recent Posts</h4>		<ul>
											<li>
					<a href="https://probablydance.com/2020/04/12/a-new-york-history-of-covid-19-written-at-the-half-way-point/">A New York History of Covid-19, Written at the Half-Way&nbsp;Point</a>
									</li>
											<li>
					<a href="https://probablydance.com/2020/03/28/a-new-strategy-genre-grows-up-survival-chaos-my-new-favorite-game/">A New Strategy Genre Grows Up: Survival Chaos, my New Favorite&nbsp;Game</a>
									</li>
											<li>
					<a href="https://probablydance.com/2020/01/29/why-video-game-ai-does-not-use-machine-learning/">Why Video Game AI does not Use Machine&nbsp;Learning</a>
									</li>
											<li>
					<a href="https://probablydance.com/2019/12/30/measuring-mutexes-spinlocks-and-how-bad-the-linux-scheduler-really-is/">Measuring Mutexes, Spinlocks and how Bad the Linux Scheduler Really&nbsp;is</a>
									</li>
											<li>
					<a href="https://probablydance.com/2019/09/11/what-happened-to-the-real-time-strategy-genre/">What Happened to the Real Time Strategy&nbsp;Genre</a>
									</li>
					</ul>
		</aside><aside id="archives-2" class="widget widget_archive"><h4 class="widget-title">Archives</h4>		<ul>
				<li><a href="https://probablydance.com/2020/04/">April 2020</a></li>
	<li><a href="https://probablydance.com/2020/03/">March 2020</a></li>
	<li><a href="https://probablydance.com/2020/01/">January 2020</a></li>
	<li><a href="https://probablydance.com/2019/12/">December 2019</a></li>
	<li><a href="https://probablydance.com/2019/09/">September 2019</a></li>
	<li><a href="https://probablydance.com/2019/08/">August 2019</a></li>
	<li><a href="https://probablydance.com/2019/06/">June 2019</a></li>
	<li><a href="https://probablydance.com/2019/04/">April 2019</a></li>
	<li><a href="https://probablydance.com/2019/03/">March 2019</a></li>
	<li><a href="https://probablydance.com/2018/06/">June 2018</a></li>
	<li><a href="https://probablydance.com/2018/05/">May 2018</a></li>
	<li><a href="https://probablydance.com/2018/04/">April 2018</a></li>
	<li><a href="https://probablydance.com/2018/01/">January 2018</a></li>
	<li><a href="https://probablydance.com/2017/12/">December 2017</a></li>
	<li><a href="https://probablydance.com/2017/11/">November 2017</a></li>
	<li><a href="https://probablydance.com/2017/10/">October 2017</a></li>
	<li><a href="https://probablydance.com/2017/09/">September 2017</a></li>
	<li><a href="https://probablydance.com/2017/08/">August 2017</a></li>
	<li><a href="https://probablydance.com/2017/02/">February 2017</a></li>
	<li><a href="https://probablydance.com/2017/01/">January 2017</a></li>
	<li><a href="https://probablydance.com/2016/12/">December 2016</a></li>
	<li><a href="https://probablydance.com/2016/11/">November 2016</a></li>
	<li><a href="https://probablydance.com/2016/06/">June 2016</a></li>
	<li><a href="https://probablydance.com/2016/04/">April 2016</a></li>
	<li><a href="https://probablydance.com/2016/03/">March 2016</a></li>
	<li><a href="https://probablydance.com/2016/02/">February 2016</a></li>
	<li><a href="https://probablydance.com/2015/12/">December 2015</a></li>
	<li><a href="https://probablydance.com/2015/09/">September 2015</a></li>
	<li><a href="https://probablydance.com/2015/07/">July 2015</a></li>
	<li><a href="https://probablydance.com/2015/06/">June 2015</a></li>
	<li><a href="https://probablydance.com/2015/05/">May 2015</a></li>
	<li><a href="https://probablydance.com/2015/02/">February 2015</a></li>
	<li><a href="https://probablydance.com/2015/01/">January 2015</a></li>
	<li><a href="https://probablydance.com/2014/12/">December 2014</a></li>
	<li><a href="https://probablydance.com/2014/11/">November 2014</a></li>
	<li><a href="https://probablydance.com/2014/10/">October 2014</a></li>
	<li><a href="https://probablydance.com/2014/09/">September 2014</a></li>
	<li><a href="https://probablydance.com/2014/08/">August 2014</a></li>
	<li><a href="https://probablydance.com/2014/06/">June 2014</a></li>
	<li><a href="https://probablydance.com/2014/05/">May 2014</a></li>
	<li><a href="https://probablydance.com/2014/04/">April 2014</a></li>
	<li><a href="https://probablydance.com/2014/03/">March 2014</a></li>
	<li><a href="https://probablydance.com/2014/02/">February 2014</a></li>
	<li><a href="https://probablydance.com/2014/01/">January 2014</a></li>
	<li><a href="https://probablydance.com/2013/10/">October 2013</a></li>
	<li><a href="https://probablydance.com/2013/09/">September 2013</a></li>
	<li><a href="https://probablydance.com/2013/08/">August 2013</a></li>
	<li><a href="https://probablydance.com/2013/05/">May 2013</a></li>
	<li><a href="https://probablydance.com/2013/02/">February 2013</a></li>
	<li><a href="https://probablydance.com/2013/01/">January 2013</a></li>
	<li><a href="https://probablydance.com/2012/12/">December 2012</a></li>
	<li><a href="https://probablydance.com/2012/11/">November 2012</a></li>
	<li><a href="https://probablydance.com/2012/10/">October 2012</a></li>
	<li><a href="https://probablydance.com/2012/08/">August 2012</a></li>
	<li><a href="https://probablydance.com/2012/07/">July 2012</a></li>
	<li><a href="https://probablydance.com/2012/04/">April 2012</a></li>
	<li><a href="https://probablydance.com/2012/03/">March 2012</a></li>
	<li><a href="https://probablydance.com/2012/02/">February 2012</a></li>
	<li><a href="https://probablydance.com/2012/01/">January 2012</a></li>
	<li><a href="https://probablydance.com/2011/10/">October 2011</a></li>
	<li><a href="https://probablydance.com/2011/09/">September 2011</a></li>
	<li><a href="https://probablydance.com/2011/08/">August 2011</a></li>
	<li><a href="https://probablydance.com/2011/07/">July 2011</a></li>
	<li><a href="https://probablydance.com/2011/06/">June 2011</a></li>
	<li><a href="https://probablydance.com/2011/05/">May 2011</a></li>
		</ul>
			</aside><aside id="categories-2" class="widget widget_categories"><h4 class="widget-title">Categories</h4>		<ul>
				<li class="cat-item cat-item-21"><a href="https://probablydance.com/category/games/">Games</a>
</li>
	<li class="cat-item cat-item-2200"><a href="https://probablydance.com/category/programming/links/">Links</a>
</li>
	<li class="cat-item cat-item-13677"><a href="https://probablydance.com/category/politics-and-economics/">Politics and Economics</a>
</li>
	<li class="cat-item cat-item-196"><a href="https://probablydance.com/category/programming/">Programming</a>
</li>
	<li class="cat-item cat-item-1"><a href="https://probablydance.com/category/uncategorized/">Uncategorized</a>
</li>
		</ul>
			</aside><aside id="meta-2" class="widget widget_meta"><h4 class="widget-title">Meta</h4>			<ul>
			<li><a href="https://wordpress.com/start?ref=wplogin">Register</a></li>			<li><a href="https://probablydance.wordpress.com/wp-login.php">Log in</a></li>
			<li><a href="https://probablydance.com/feed/">Entries feed</a></li>
			<li><a href="https://probablydance.com/comments/feed/">Comments feed</a></li>
			<li><a href="https://wordpress.com/" title="Powered by WordPress, state-of-the-art semantic personal publishing platform.">WordPress.com</a></li>			</ul>
			</aside>	</div>
	
	
</div>
	<!-- Search Field -->
	<div class="footer-content">
		<form method="get" id="searchform" action="https://probablydance.com/">
			<div id="search">
				<input type="text" value="" name="s" id="s">
				<input type="submit" id="searchsubmit" value="Search">
			</div>
		</form>
		<p>
			<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a>
					</p>
	</div>
</div><!-- #footer -->

<!--  -->
<script src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/gprofiles.js"></script>
<script>
var WPGroHo = {"my_hash":""};
</script>
<script type="text/javascript" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/wpgroho.js"></script>

	<script>
		//initialize and attach hovercards to all gravatars
		jQuery( document ).ready( function( $ ) {

			if (typeof Gravatar === "undefined"){
				return;
			}

			if ( typeof Gravatar.init !== "function" ) {
				return;
			}			

			Gravatar.profile_cb = function( hash, id ) {
				WPGroHo.syncProfileData( hash, id );
			};
			Gravatar.my_hash = WPGroHo.my_hash;
			Gravatar.init( 'body', '#wp-admin-bar-my-account' );
		});
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-866ac17d713ed49c713e14e9b4ba34ab">
	</div>
	<div class="grofile-hash-map-32d3ef171bc897317c4a77a83f44fbcb">
	</div>
	<div class="grofile-hash-map-e214f5c143b40458c473bef6ee05823e">
	</div>
	<div class="grofile-hash-map-e31d7c3f1f052f5694a083055887156b">
	</div>
	<div class="grofile-hash-map-6568504bfd4f071c1847be37aaf20ec3">
	</div>
	<div class="grofile-hash-map-c2a2c0b6dd4808989adcd863123fa585">
	</div>
	<div class="grofile-hash-map-bf239d8fd2063bb9776944028e649c62">
	</div>
	<div class="grofile-hash-map-31ccee0370328a7c894902c0a70373f7">
	</div>
	<div class="grofile-hash-map-522e14016606fa348941f854ddd5fb8c">
	</div>
	<div class="grofile-hash-map-3c83b477629072469dc3898e1629024f">
	</div>
	<div class="grofile-hash-map-4ccf320bd016b7a6cdd8c75bbba88cab">
	</div>
	</div>
<script>
var HighlanderComments = {"loggingInText":"Logging In\u2026","submittingText":"Posting Comment\u2026","postCommentText":"Post Comment","connectingToText":"Connecting to %s","commentingAsText":"%1$s: You are commenting using your %2$s account.","logoutText":"Log Out","loginText":"Log In","connectURL":"https:\/\/probablydance.wordpress.com\/public.api\/connect\/?action=request&domain=probablydance.com","logoutURL":"https:\/\/probablydance.wordpress.com\/wp-login.php?action=logout&_wpnonce=1312e779fa","homeURL":"https:\/\/probablydance.com\/","postID":"2435","gravDefault":"identicon","enterACommentError":"Please enter a comment","enterEmailError":"Please enter your email address here","invalidEmailError":"Invalid email address","enterAuthorError":"Please enter your name here","gravatarFromEmail":"This picture will show whenever you leave a comment. Click to customize it.","logInToExternalAccount":"Log in to use details from one of these accounts.","change":"Change","changeAccount":"Change Account","comment_registration":"","userIsLoggedIn":"","isJetpack":"","text_direction":"ltr"};
</script>
<script type="text/javascript" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(6)"></script>

	<div id="carousel-reblog-box">
		<form action="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#" name="carousel-reblog">
			<textarea id="carousel-reblog-content" name="carousel-reblog-content" placeholder="Add your thoughts here... (optional)"></textarea>
			<label for="carousel-reblog-to-blog-id" id="carousel-reblog-lblogid">Post to</label>
			<select name="carousel-reblog-to-blog-id" id="carousel-reblog-to-blog-id">
						</select>

			<div class="submit">
				<span class="canceltext"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#" class="cancel">Cancel</a></span>
				<input type="submit" name="carousel-reblog-submit" class="button" id="carousel-reblog-submit" value="Reblog Post">
				<input type="hidden" id="carousel-reblog-blog-id" value="22872755">
				<input type="hidden" id="carousel-reblog-blog-url" value="https://probablydance.com">
				<input type="hidden" id="carousel-reblog-blog-title" value="Probably Dance">
				<input type="hidden" id="carousel-reblog-post-url" value="">
				<input type="hidden" id="carousel-reblog-post-title" value="">
			</div>

			<input type="hidden" id="_wpnonce" name="_wpnonce" value="112b04ff7d"><input type="hidden" name="_wp_http_referer" value="/2016/04/30/neural-networks-are-impressively-good-at-compression/">		</form>

		<div class="arrow"></div>
	</div>

	<script type="text/javascript">
		window.WPCOM_sharing_counts = {"https:\/\/probablydance.com\/2016\/04\/30\/neural-networks-are-impressively-good-at-compression\/":2435};
	</script>
				<link rel="stylesheet" id="all-css-0-3" href="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(7)" type="text/css" media="all">
<script>
var actionbardata = {"siteID":"22872755","siteName":"Probably Dance","siteURL":"https:\/\/probablydance.com","icon":"<img alt='' src='https:\/\/s0.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/manifest","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&signup_flow=account&domain=probablydance.com","themeURL":"","xhrURL":"https:\/\/probablydance.com\/wp-admin\/admin-ajax.php","nonce":"35c0996a15","isSingular":"1","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"6dabac271c\" \/>","referer":"https:\/\/probablydance.com\/2016\/04\/30\/neural-networks-are-impressively-good-at-compression\/","canFollow":"1","feedID":"1759169","statusMessage":"","customizeLink":"https:\/\/probablydance.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fprobablydance.wordpress.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F","postID":"2435","shortlink":"https:\/\/wp.me\/p1xYfp-Dh","canEditPost":"","editLink":"https:\/\/wordpress.com\/post\/probablydance.com\/2435","statsLink":"https:\/\/wordpress.com\/stats\/post\/2435\/probablydance.com","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Manifest","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/read\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 134 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&signup_flow=account&domain=probablydance.com\">Log in now.<\/a>","stats":"Stats"}};
</script>
<script>
var jetpackCarouselStrings = {"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/probablydance.com\/wp-admin\/admin-ajax.php","nonce":"2655817af9","display_exif":"1","display_geo":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post Comment","write_comment":"Write a Comment...","loading_comments":"Loading Comments...","download_original":"View full size <span class=\"photo-size\">{0}<span class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please be sure to submit some text with your comment.","no_comment_email":"Please provide an email address to comment.","no_comment_author":"Please provide your name to comment.","comment_post_error":"Sorry, but there was an error posting your comment. Please try again later.","comment_approved":"Your comment was approved.","comment_unapproved":"Your comment is in moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter Speed","focal_length":"Focal Length","copyright":"Copyright","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/probablydance.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F","blog_id":"22872755","meta_data":["camera","aperture","shutter_speed","focal_length","copyright"],"local_comments_commenting_as":"<fieldset><label for=\"email\">Email (Required)<\/label> <input type=\"text\" name=\"email\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-email-field\" \/><\/fieldset><fieldset><label for=\"author\">Name (Required)<\/label> <input type=\"text\" name=\"author\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-author-field\" \/><\/fieldset><fieldset><label for=\"url\">Website<\/label> <input type=\"text\" name=\"url\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-url-field\" \/><\/fieldset>","reblog":"Reblog","reblogged":"Reblogged","reblog_add_thoughts":"Add your thoughts here... (optional)","reblogging":"Reblogging...","post_reblog":"Post Reblog","stats_query_args":"blog=22872755&v=wpcom&tz=-7&user_id=0&subd=probablydance","is_public":"1","reblog_enabled":""};
</script>
<script>
var sharing_js_options = {"lang":"en","counts":"1","is_stats_active":"1"};
</script>
<script type="text/javascript" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/saved_resource(8)"></script><div id="actionbar" class="actnbr-pub-manifest actnbr-has-follow"><ul><li class="actnbr-btn actnbr-hidden"> 			    	<a class="actnbr-action actnbr-actn-follow" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/"><svg class="gridicon gridicon__follow" height="24px" width="24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M23 16v2h-3v3h-2v-3h-3v-2h3v-3h2v3h3zM20 2v9h-4v3h-3v4H4c-1.1 0-2-.9-2-2V2h18zM8 13v-1H4v1h4zm3-3H4v1h7v-1zm0-2H4v1h7V8zm7-4H4v2h14V4z"></path></g></svg><span>Follow</span></a> 			    	<div class="actnbr-popover tip tip-top-left actnbr-notice"> 			    		<div class="tip-arrow"></div> 			    		<div class="tip-inner actnbr-follow-bubble"></div> 			    	</div> 			    </li><li class="actnbr-ellipsis actnbr-hidden"> 			  <svg class="gridicon gridicon__ellipsis" height="24" width="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><circle cx="5" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="12" cy="12" r="2"></circle></g></svg> 			  <div class="actnbr-popover tip tip-top-left actnbr-more"> 			  	<div class="tip-arrow"></div> 			  	<div class="tip-inner"> 				  <ul> 				    <li class="actnbr-sitename"><a href="https://probablydance.com/"><img alt="" src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/wpcom-gray-white.png" class="avatar avatar-50" height="50" width="50"> Probably Dance</a></li> 				   	<li class="actnbr-folded-customize"><a href="https://probablydance.wordpress.com/wp-admin/customize.php?url=https%3A%2F%2Fprobablydance.wordpress.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F"><svg class="gridicon gridicon__customize" height="20px" width="20px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M2 6c0-1.505.78-3.08 2-4 0 .845.69 2 2 2 1.657 0 3 1.343 3 3 0 .386-.08.752-.212 1.09.74.594 1.476 1.19 2.19 1.81L8.9 11.98c-.62-.716-1.214-1.454-1.807-2.192C6.753 9.92 6.387 10 6 10c-2.21 0-4-1.79-4-4zm12.152 6.848l1.34-1.34c.607.304 1.283.492 2.008.492 2.485 0 4.5-2.015 4.5-4.5 0-.725-.188-1.4-.493-2.007L18 9l-2-2 3.507-3.507C18.9 3.188 18.225 3 17.5 3 15.015 3 13 5.015 13 7.5c0 .725.188 1.4.493 2.007L3 20l2 2 6.848-6.848c1.885 1.928 3.874 3.753 5.977 5.45l1.425 1.148 1.5-1.5-1.15-1.425c-1.695-2.103-3.52-4.092-5.448-5.977z" data-reactid=".2.1.1:0.1b.0"></path></g></svg><span>Customize<span></span></span></a></li> 				    <li class="actnbr-folded-follow"><a class="actnbr-action actnbr-actn-follow" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/"><svg class="gridicon gridicon__follow" height="24px" width="24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M23 16v2h-3v3h-2v-3h-3v-2h3v-3h2v3h3zM20 2v9h-4v3h-3v4H4c-1.1 0-2-.9-2-2V2h18zM8 13v-1H4v1h4zm3-3H4v1h7v-1zm0-2H4v1h7V8zm7-4H4v2h14V4z"></path></g></svg><span>Follow</span></a></li> 					<li class="actnbr-signup"><a href="https://wordpress.com/start/">Sign up</a></li> 				    <li class="actnbr-login"><a href="https://wordpress.com/log-in?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&amp;signup_flow=account&amp;domain=probablydance.com">Log in</a></li> 				     				    <li class="actnbr-shortlink"><a href="https://wp.me/p1xYfp-Dh">Copy shortlink</a></li> 				    <li class="flb-report"><a href="http://en.wordpress.com/abuse/">Report this content</a></li> 				     				     				    <li class="actnbr-subs"><a href="https://subscribe.wordpress.com/">Manage subscriptions</a></li> 				    <li class="actnbr-fold"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/">Collapse this bar</a></li> 			      </ul> 			    </div> 		      </div> 		    </li> 	      </ul></div>
<script type="text/javascript">
( 'fetch' in window ) || document.write( '<script src="https://s0.wp.com/wp-includes/js/dist/vendor/wp-polyfill-fetch.min.js?m=1573572739h&#038;ver=3.0.0"></scr' + 'ipt>' );( document.contains ) || document.write( '<script src="https://s0.wp.com/wp-includes/js/dist/vendor/wp-polyfill-node-contains.min.js?m=1540208548h&#038;ver=3.42.0"></scr' + 'ipt>' );( window.DOMRect ) || document.write( '<script src="https://s0.wp.com/wp-includes/js/dist/vendor/wp-polyfill-dom-rect.min.js?m=1585663916h&#038;ver=3.42.0"></scr' + 'ipt>' );( window.URL && window.URL.prototype && window.URLSearchParams ) || document.write( '<script src="https://s0.wp.com/wp-includes/js/dist/vendor/wp-polyfill-url.min.js?m=1585663916h&#038;ver=3.6.4"></scr' + 'ipt>' );( window.FormData && window.FormData.prototype.keys ) || document.write( '<script src="https://s0.wp.com/wp-includes/js/dist/vendor/wp-polyfill-formdata.min.js?m=1550600082h&#038;ver=3.0.12"></scr' + 'ipt>' );( Element.prototype.matches && Element.prototype.closest ) || document.write( '<script src="https://s0.wp.com/wp-includes/js/dist/vendor/wp-polyfill-element-closest.min.js?m=1540208548h&#038;ver=2.0.2"></scr' + 'ipt>' );
( window.URL && window.URL.prototype && window.URLSearchParams ) || document.write( '<script src="https://s0.wp.com/wp-content/plugins/gutenberg-core/7.8.1/vendor/wp-polyfill-url.min.7490158b.js?m=1586214842h&#038;ver=3.6.4"></scr' + 'ipt>' );
( window.DOMRect ) || document.write( '<script src="https://s0.wp.com/wp-content/plugins/gutenberg-core/7.8.1/vendor/wp-polyfill-dom-rect.7e21c103.js?m=1586214842h&#038;ver=3.42.0"></scr' + 'ipt>' );
</script>
<script type="text/javascript">
var windowOpen;
			jQuery( document.body ).on( 'click', 'a.share-twitter', function() {
				// If there's another sharing window open, close it.
				if ( 'undefined' !== typeof windowOpen ) {
					windowOpen.close();
				}
				windowOpen = window.open( jQuery( this ).attr( 'href' ), 'wpcomtwitter', 'menubar=1,resizable=1,width=600,height=350' );
				return false;
			});
var windowOpen;
			jQuery( document.body ).on( 'click', 'a.share-facebook', function() {
				// If there's another sharing window open, close it.
				if ( 'undefined' !== typeof windowOpen ) {
					windowOpen.close();
				}
				windowOpen = window.open( jQuery( this ).attr( 'href' ), 'wpcomfacebook', 'menubar=1,resizable=1,width=600,height=400' );
				return false;
			});
</script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script>		<iframe src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/master.html" scrolling="no" id="likes-master" name="likes-master" style="display:none;"></iframe>
		<div id="likes-other-gravatars"><div class="likes-text"><span>%d</span> bloggers like this:</div><ul class="wpl-avatars sd-like-gravatars"></ul></div>
<script src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/w.js" type="text/javascript" async="" defer=""></script>
<script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'22872755','blog_tz':'-7','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'22872755','v':'wpcom','tz':'-7','user_id':'0','post':'2435','subd':'probablydance'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGRVYVNrSFguN3FwSmQ5RGtNX3VQcj1yVzhiflM1THQtLGFdQ2toOXYlSHRwW3lOSlk5cVNSfnJIX21fV01OJiV3cixaZ1Vnd2FoamgtJSZbLTksJmlVdiZ4MW04LVVtVG12bEl+bixZWFtwcGViVFQ5Rz9bcV9BTFZOUWllK1JEMW1CbXdVdlRpajQwTkNKZnh6aXx1SU12NnNLai9LOGlsYTd6JmFwQm1ILjZwd3hJQ1hFY0h+VU5KNktzLHJ3YlJyTUguWl1oY2NHeFM/P2JHbC1UNlBNNitzaD9adyV2U3UweGtZSDVrZT03blthZnZ1VUl6NU5tSDR3eHg='}]);
_stq.push([ 'clickTrackerInit', '22872755', '2435' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:0px;width:0px;overflow:hidden" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>

<img src="./Neural Networks Are Impressively Good At Compression _ Probably Dance_files/g.gif" alt=":)" id="wpstats"></body></html>